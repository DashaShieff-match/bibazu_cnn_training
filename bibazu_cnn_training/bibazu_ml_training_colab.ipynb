{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cX40CBaH_5h-",
        "outputId": "0116ec27-c4f2-449b-afc5-5ceff94fb8cb"
      },
      "outputs": [],
      "source": [
        "# load example data from github\n",
        "!git clone https://github.com/match-Aero/bibazu_example_data.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# downgrade tensorflow for compatibility with local machine\n",
        "%pip install tensorflow==2.10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoRlgguU_e_x"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "print(\"keras:\",keras.__version__)\n",
        "print(\"tf:\",tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkJIZnP4_e_y"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "%load_ext tensorboard\n",
        "log_dir = os.path.join(os.getcwd(),\"logs\",\"fit\",datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtXg2d1C_e_z"
      },
      "outputs": [],
      "source": [
        "#function to plot 9 samples from dataset\n",
        "def plot_samples(dataset,title):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.suptitle(title)\n",
        "    for images, labels in dataset.take(1):\n",
        "        for i in range(9):\n",
        "            ax = plt.subplot(3, 3, i + 1)\n",
        "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "            plt.title(int(np.argmax(labels[i])))\n",
        "            plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfRMFf2a_e_z"
      },
      "outputs": [],
      "source": [
        "#standard paths\n",
        "synthetic_ds_path = \"bibazu_example_data/dataset/Rk2i_synthetic/\"\n",
        "real_ds_path = \"bibazu_example_data/dataset/Rk2i_real/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHh8oOc1_e_0",
        "outputId": "f2cf49fb-3eb2-4d00-ed0e-5decb5d800c2"
      },
      "outputs": [],
      "source": [
        "#load images into batched dataset objects\n",
        "\n",
        "#dataset parameters\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "validation_split = 0.2\n",
        "\n",
        "train_batch_size = 20\n",
        "val_batch_size = 5\n",
        "test_batch_size = 1\n",
        "\n",
        "#synthetic dataset for training and validation\n",
        "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=synthetic_ds_path,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    batch_size=train_batch_size,\n",
        "    validation_split = validation_split,\n",
        "    subset = 'training',\n",
        "    seed = 10,\n",
        "    color_mode = 'rgb',\n",
        "    #shuffle = False,\n",
        "    image_size=(img_height, img_width))\n",
        "\n",
        "val_ds = keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=synthetic_ds_path,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    batch_size=val_batch_size,\n",
        "    validation_split = validation_split,\n",
        "    subset = 'validation',\n",
        "    seed = 10,\n",
        "    color_mode = 'rgb',\n",
        "    #shuffle = False,\n",
        "    image_size=(img_height, img_width))\n",
        "\n",
        "#real dataset for testing trained model\n",
        "test_ds = keras.preprocessing.image_dataset_from_directory(\n",
        "    directory=real_ds_path,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    batch_size=test_batch_size,\n",
        "    color_mode = 'rgb',\n",
        "    shuffle = False,\n",
        "    image_size=(img_height, img_width))\n",
        "\n",
        "#plot_samples(train_ds,\"pre-augmentation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeKw1vUn_e_1"
      },
      "outputs": [],
      "source": [
        "#get number of classes for output layer size\n",
        "dataset_labels = train_ds.class_names\n",
        "num_classes = len(dataset_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di3BZhaz_e_1"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "test_ds = test_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5QH9t2e_e_1"
      },
      "outputs": [],
      "source": [
        "#augmentations\n",
        "#augmentations can also be added as layer to the model, it is then performed by the GPU\n",
        "\n",
        "#define augmentation set\n",
        "data_augmentation = keras.Sequential([\n",
        "        layers.RandomRotation(0.025),\n",
        "        layers.RandomBrightness(0.4),\n",
        "        layers.RandomContrast(0.2),\n",
        "        layers.RandomTranslation(0.1,0.1),\n",
        "        layers.RandomZoom(0.1)\n",
        "        ])\n",
        "\n",
        "#apply augmentation set to training dataset\n",
        "train_ds_augmentend = train_ds.map(\n",
        "    lambda img, label: (data_augmentation(img), label),\n",
        "    num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "#plot_samples(train_ds_augmentend,\"augmented\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LOgMR3u_e_2"
      },
      "outputs": [],
      "source": [
        "normalization_layer = layers.Rescaling(1./255)\n",
        "train_ds_augmentend = train_ds_augmentend.map(lambda x, y: (normalization_layer(x), y))\n",
        "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "#plot_samples(train_ds_augmentend,\"augmented\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TApp5lky_e_3",
        "outputId": "76022f46-d42c-478f-9247-bb6629d1643a"
      },
      "outputs": [],
      "source": [
        "#load an empty MobileNet model\n",
        "model = keras.applications.mobilenet.MobileNet()\n",
        "\n",
        "#remove last 4 layers (determined in fine tuning)\n",
        "x = model.layers[-5].output\n",
        "\n",
        "#set proper size for last layer\n",
        "x = tf.keras.layers.Reshape(target_shape=(1024,))(x)\n",
        "\n",
        "#add dense-layer as output\n",
        "output = tf.keras.layers.Dense(units=num_classes, activation='softmax')(x)\n",
        "\n",
        "#set input and output layers\n",
        "model = keras.models.Model(inputs=model.input, outputs=output)\n",
        "\n",
        "#compile model, set learning parameters\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT1mevI__e_3",
        "outputId": "2940a8b2-7f5a-4d0d-a499-82190e7c32d0"
      },
      "outputs": [],
      "source": [
        "#training\n",
        "history = model.fit(x=train_ds_augmentend,\n",
        "            steps_per_epoch=len(train_ds),\n",
        "            validation_data=val_ds,\n",
        "            validation_steps=len(val_ds),\n",
        "            epochs=200,\n",
        "            callbacks=[tensorboard_callback],\n",
        "            verbose=2\n",
        "           )\n",
        "            #tf: 6m 20s  callbacks=[tensorboard_callback]\n",
        "            #ohnetf: 3m45s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "EtMrUEiW_e_3",
        "outputId": "2e43f835-edec-4c14-918f-9f220ed843c5"
      },
      "outputs": [],
      "source": [
        "#plot training history\n",
        "plt.style.use(\"ggplot\")\n",
        "fig,axs = plt.subplots(1,2)\n",
        "\n",
        "fig.set_figheight(2.5)\n",
        "fig.set_figwidth(10)\n",
        "\n",
        "axs[0].plot(history.history['accuracy'])\n",
        "axs[0].plot(history.history['val_accuracy'])\n",
        "axs[0].set_title('model accuracy')\n",
        "axs[0].set_ylabel('accuracy')\n",
        "axs[0].set_xlabel('epoch')\n",
        "axs[0].legend(['train', 'val'], loc='lower right')\n",
        "\n",
        "axs[1].plot(history.history['loss'])\n",
        "axs[1].plot(history.history['val_loss'])\n",
        "axs[1].set_title('model loss')\n",
        "axs[1].set_ylabel('loss')\n",
        "axs[1].set_xlabel('epoch')\n",
        "axs[1].legend(['train', 'val'], loc='upper right')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONnvGEVs_e_4",
        "outputId": "a34644f0-e62c-40cb-ef8b-bddd2e69ad77"
      },
      "outputs": [],
      "source": [
        "#save model\n",
        "model_save_path = \"trained_models\"\n",
        "\n",
        "if not model_save_path == \"\":\n",
        "    keras.models.save_model(model,model_save_path)\n",
        "    print(\"model saved to\", model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtOODAtz_e_4"
      },
      "outputs": [],
      "source": [
        "#load previously trained model\n",
        "model_load_path = model_save_path\n",
        "\n",
        "if not model_load_path == \"\":\n",
        "    model = keras.models.load_model(model_load_path,compile=False)\n",
        "    model.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qgaAwbq_e_4",
        "outputId": "fceac25f-3b5f-4217-b142-7a7c1935f663"
      },
      "outputs": [],
      "source": [
        "#do prediction on real dataset\n",
        "prediction_ds = test_ds #dataset to perform prediction on\n",
        "\n",
        "test_predictions = model.predict(x=prediction_ds, steps=len(prediction_ds), verbose=2)\n",
        "predicted_labels = test_predictions.argmax(axis=1) #get labes for predictions\n",
        "\n",
        "#get true labels from real dataset\n",
        "ds_true_labes = tf.concat([y for x, y in prediction_ds], axis=0)\n",
        "ds_true_labes = np.argmax(ds_true_labes, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "83At0smg_e_4",
        "outputId": "3821bf4c-19ab-42ad-86ab-ac800fa14aa9"
      },
      "outputs": [],
      "source": [
        "#calculate confusion matrix\n",
        "cm = confusion_matrix(y_true=ds_true_labes, y_pred=predicted_labels)\n",
        "\n",
        "#plot confusion matrix\n",
        "cm_plot = ConfusionMatrixDisplay(confusion_matrix = cm,display_labels = dataset_labels)\n",
        "cm_plot.plot(cmap= plt.cm.Blues)\n",
        "plt.grid(None)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2089694cd97b06a8c1e749cea34ae9e2c716ec386c0ef8829d89575f5f3f420d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
